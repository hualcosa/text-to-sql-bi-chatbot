{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8ea52862-289b-4a5d-8417-a6657f48ab72",
   "metadata": {},
   "source": [
    "# 4-LangGraph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8db9ca5f-b88c-45a8-83ff-292363fe48e5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip install langgraph -q --disable-pip-version-check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34429d93-ec82-4135-919a-f1cec3812d6a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import boto3\n",
    "import pandas as pd\n",
    "redshift_client = boto3.client('redshift-data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49386f1a-8e9c-4460-af71-e77618a040d2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%run ../utilities/utils.py\n",
    "%run ../utilities/prompt_utils.py\n",
    "%run ../utilities/bedrock_utils.py\n",
    "%run ../utilities/database_utils.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "504e02d4-98d2-420f-91e4-4664f8ed7a28",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from IPython.display import Image, display\n",
    "def visualize_graph(graph):\n",
    "    try:\n",
    "        display(Image(graph.get_graph().draw_mermaid_png()))\n",
    "    except Exception:\n",
    "        # This requires some extra dependencies and is optional\n",
    "        pass\n",
    "    return"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc9eb787-6b9a-4b81-ad24-309a297e560c",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Low-complexity graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de6a02b8-daf9-4553-9ed7-acd74ef20e07",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from typing import Annotated\n",
    "from typing_extensions import TypedDict\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "from langgraph.graph.message import add_messages\n",
    "\n",
    "class BaseState(TypedDict):\n",
    "    # Messages have the type \"list\". The `add_messages` function\n",
    "    # in the annotation defines how this state key should be updated\n",
    "    # (in this case, it appends messages to the list, rather than overwriting them)\n",
    "    messages: Annotated[list, add_messages]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f5802dd-b6a3-4e24-b653-c297697625d7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def create_simple_graph():\n",
    "    graph_builder = StateGraph(BaseState)\n",
    "    \n",
    "    def get_context(state: BaseState):\n",
    "        # When context is already extracted to file, read from file.\n",
    "        # If not, extrac context.\n",
    "        context_file_path = \"db_schema.txt\"\n",
    "        if os.path.exists(context_file_path):\n",
    "            with open(context_file_path, \"r\") as f:\n",
    "                db_schema = f.read()\n",
    "        else:            \n",
    "            schemas_dict = get_all_table_schema()\n",
    "            db_schema = \"\\n\\n\".join(schemas_dict)\n",
    "            \n",
    "            with open(context_file_path, \"w\") as f:\n",
    "                f.write(db_schema)\n",
    "        return {\n",
    "            \"messages\": state[\"messages\"] + [db_schema]\n",
    "        }\n",
    "    \n",
    "    # The first argument is the unique node name\n",
    "    # The second argument is the function or object that will be called whenever\n",
    "    # the node is used.\n",
    "    graph_builder.add_node(\"context\", get_context)\n",
    "    \n",
    "    # This tells our graph how to navigate through the graph.\n",
    "    # The first argument is the source and second argument is the sink.\n",
    "    # Direction of graph: source --> sink.\n",
    "    graph_builder.add_edge(START, \"context\")\n",
    "    graph_builder.add_edge(\"context\", END)\n",
    "    graph = graph_builder.compile()\n",
    "    \n",
    "    return graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "602b0a54-eff0-4cf9-934c-c621986ef2c8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "simple_graph = create_simple_graph()\n",
    "visualize_graph(simple_graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5816199-cc9a-4ceb-b6c7-5c073ba12ad4",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "result = simple_graph.invoke(BaseState(messages=[]))\n",
    "print(f\"Simple graph result: {result}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fadd1f65-063c-4b60-9da8-a0d7a6f340a4",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Medium-complexity graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bd8e6f3-3bdd-4933-b1a8-f70475059fe8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class SqlState(TypedDict):\n",
    "    # Messages have the type \"list\". The `add_messages` function\n",
    "    # in the annotation defines how this state key should be updated\n",
    "    # (in this case, it appends messages to the list, rather than overwriting them)\n",
    "    user_input: str\n",
    "    num_sql_attempt: int\n",
    "    if_sql_valid: bool\n",
    "    context: str\n",
    "    sql_query: str\n",
    "    feedback: str\n",
    "    error: str\n",
    "    data: pd.DataFrame\n",
    "    if_viz_success: bool\n",
    "    viz_code: str\n",
    "    response: str\n",
    "#    response: Annotated[list, add_messages]\n",
    "    \n",
    "def create_sql_graph():\n",
    "    graph_builder = StateGraph(SqlState)\n",
    "    \n",
    "    def get_context(state: BaseState):\n",
    "        # When context is already extracted to file, read from file.\n",
    "        # If not, extrac context.\n",
    "        context_file_path = \"db_schema.txt\"\n",
    "        if os.path.exists(context_file_path):\n",
    "            with open(context_file_path, \"r\") as f:\n",
    "                db_schema = f.read()\n",
    "        else:            \n",
    "            schemas_dict = get_all_table_schema()\n",
    "            db_schema = \"\\n\\n\".join(schemas_dict)\n",
    "            \n",
    "            with open(context_file_path, \"w\") as f:\n",
    "                f.write(db_schema)\n",
    "        return {\n",
    "            \"context\": db_schema\n",
    "        }\n",
    "    \n",
    "    def run_query_no_feedback_wrapper(state: SqlState):\n",
    "        print(\"Running txt2sql...\")\n",
    "        if_passed, response, sql_query, current_attempt = run_query_no_feedback(question = state[\"user_input\"], \n",
    "                                                                                db_schema = state[\"context\"],\n",
    "                                                                               prompt_callback=None)\n",
    "        \n",
    "        update = {\n",
    "            \"num_sql_attempt\": current_attempt,\n",
    "            \"if_passed\": if_passed,\n",
    "            \"sql_query\": sql_query,\n",
    "            \"feedback\": \"\",\n",
    "        }\n",
    "        \n",
    "        if if_passed:\n",
    "            update['data'] = response\n",
    "        else:\n",
    "            update['error'] = response['Error']\n",
    "\n",
    "        return update\n",
    "    \n",
    "    def run_query_with_feedback_wrapper(state: SqlState):\n",
    "        \n",
    "        if_passed, current_feedback, response, sql_query, current_attempt = run_query_with_feedback(user_query = state[\"user_input\"], \n",
    "                                                                                                    prev_feedback = state[\"feedback\"],\n",
    "                                                                                                    prev_sql_query = state[\"sql_query\"], \n",
    "                                                                                                    prev_response = {\"Error\": state['error']}, \n",
    "                                                                                                    num_attempt = state[\"num_sql_attempt\"], \n",
    "                                                                                                    db_schema= state[\"context\"])\n",
    "        update = {\n",
    "            \"num_sql_attempt\": current_attempt,\n",
    "            \"if_passed\": if_passed,\n",
    "            \"sql_query\": sql_query,\n",
    "            \"feedback\": current_feedback,\n",
    "        }\n",
    "        \n",
    "        if if_passed:\n",
    "            update['data'] = response\n",
    "        else:\n",
    "            update['error'] = response['Error']\n",
    "\n",
    "        return update\n",
    "        \n",
    "    def check_for_valid_sql(state: SqlState):\n",
    "        max_attempts = 10\n",
    "        if state['if_passed']:\n",
    "            return 'valid'\n",
    "        elif state['num_sql_attempt'] == max_attempts:\n",
    "            return 'max_attempt_reached'\n",
    "        else:\n",
    "            return 'not_valid'\n",
    "        \n",
    "    def generate_viz_wrapper(state: SqlState):\n",
    "        \n",
    "        if_viz_success, viz_code = generate_viz_v1(sql_query = state['sql_query'], execute=False)\n",
    "        \n",
    "        return {\"if_viz_success\": if_viz_success, \"viz_code\":viz_code}\n",
    "        \n",
    "    \n",
    "    \n",
    "    def generate_response(state: SqlState):\n",
    "        \n",
    "        prompt_template = \"\"\"Generate a natural language response to the <quesiton> below using the <data_table>.\n",
    "        \n",
    "<data_table>\n",
    "{data_table}\n",
    "</data_table>\n",
    "\n",
    "<question>\n",
    "{question}\n",
    "</question>\n",
    "        \"\"\"\n",
    "        prompt = prompt_template.format(question=state['user_input'], data_table=state['data'].to_string())\n",
    "        response = invoke_model(prompt, SONNET35_MODEL_ID)\n",
    "        \n",
    "        return {\"response\" : response}\n",
    "        \n",
    "    \n",
    "    # The first argument is the unique node name\n",
    "    # The second argument is the function or object that will be called whenever\n",
    "    # the node is used.\n",
    "    graph_builder.add_node(\"get_context\", get_context)\n",
    "    graph_builder.add_node(\"txt_to_sql\", run_query_no_feedback_wrapper)\n",
    "    graph_builder.add_node(\"fix_sql\", run_query_with_feedback_wrapper)\n",
    "    graph_builder.add_node(\"sql_to_viz\", generate_viz_wrapper)\n",
    "    graph_builder.add_node(\"generate_response\", generate_response)\n",
    "    \n",
    "    graph_builder.add_edge(START, \"get_context\")\n",
    "    graph_builder.add_edge(\"get_context\", \"txt_to_sql\")\n",
    "    graph_builder.add_conditional_edges('txt_to_sql', check_for_valid_sql, {\n",
    "        \"valid\" : \"sql_to_viz\", \n",
    "        \"not_valid\" : \"fix_sql\"\n",
    "    })\n",
    "    \n",
    "    \n",
    "    \n",
    "    graph_builder.add_conditional_edges('fix_sql', check_for_valid_sql, {\n",
    "        \"valid\" : \"sql_to_viz\", \n",
    "        \"not_valid\" : \"fix_sql\",\n",
    "        \"max_attempt_reached\": END\n",
    "    })\n",
    "    graph_builder.add_edge(\"sql_to_viz\", \"generate_response\")\n",
    "    graph_builder.add_edge(\"generate_response\", END)\n",
    "    \n",
    "    graph = graph_builder.compile()\n",
    "    \n",
    "    return graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dd2b5b2-9df6-4a2c-a9c1-147d8930ae84",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sql_graph = create_sql_graph()\n",
    "visualize_graph(sql_graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c5b89e4-44f4-4823-8840-b443ee297aeb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "usr_query = \"How many games were played each year?\"\n",
    "# usr_query = \"How has the average height of the players changed over the decades?\"\n",
    "result = sql_graph.invoke(SqlState(user_input=usr_query, num_sql_attempt=0))\n",
    "print(result['response'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba768984-b3af-4e08-82ef-651709af4b1a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "result['data']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d3af67f-d985-4911-9102-df32637cea0b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(result['viz_code'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bfec0ef-a8e2-491b-9e42-6ba4918efffd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "exec(result['viz_code'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ee7af3f-2ac1-42e8-86cd-8ee2d158154a",
   "metadata": {},
   "source": [
    "## Future extensions\n",
    "\n",
    "* Agentic workflows:\n",
    "    * Opportunity: Use functions as tools and use agents to orchestrate the workflow\n",
    "* Attempts:\n",
    "    * Challenge: When the solution is going down a rabbit hole (i.e. similar to optimizing over a local minimum/maximum)\n",
    "    * Solution1: Instead of fixing the sql, try generating a new sql. \n",
    "    * Solution2: Change temperature to introduce randomness/change.\n",
    "    * Solution3: Use LLM to rewrite the user query"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
